{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/media/vijinim/data/Experiments/Data/FUDAN/Uniprot-12/\"\n",
    "\n",
    "# kraken2 --confidence 0.1 \n",
    "# https://www.biostars.org/p/402619/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xlsxwriter\n",
    "import collections\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get contig lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_lengths = {}\n",
    "\n",
    "for index, record in enumerate(SeqIO.parse(project_path+\"final.contigs.fa\", \"fasta\")):\n",
    "    contig_lengths[record.id] = len(record.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get kraken result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_total_len = {}\n",
    "\n",
    "species_names_taxid = {}\n",
    "\n",
    "taxid_list = []\n",
    "\n",
    "contig_taxid = {}\n",
    "\n",
    "taxid_contigs = {}\n",
    "\n",
    "taxid_to_species = {}\n",
    "\n",
    "species_names_taxid_length = {}\n",
    "\n",
    "with open(project_path+\"MEGAHIT_new_kraken_res_0.1.txt\", \"r\") as myfile:\n",
    "    for line in myfile.readlines():\n",
    "        strings = line.strip().split(\"\\t\")\n",
    "        \n",
    "        if strings[0] == \"C\":\n",
    "            \n",
    "            species_strings = strings[2].split(\" \")\n",
    "            \n",
    "            if len(species_strings) > 3 and \"unclassified\" not in strings[2] and \"complex\" not in strings[2] and \" group \" not in strings[2] and \"Human\" not in strings[2] and \"phage\" not in strings[2] and \"cellular organisms\" not in strings[2]:\n",
    "                \n",
    "                taxid = species_strings[-1][:-1]\n",
    "                \n",
    "                my_species = \"\"\n",
    "                \n",
    "                if species_strings[0] == \"Candidatus\":\n",
    "                    my_species = species_strings[0] + \" \" + species_strings[1] + \" \" + species_strings[2]\n",
    "                    \n",
    "                elif species_strings[1] != \"sp.\":\n",
    "                    my_species = species_strings[0] + \" \" + species_strings[1]\n",
    "                elif \"(taxid\" not in species_strings[3]:\n",
    "                    my_species = strings[2].split(\"(taxid\")[0]\n",
    "                    \n",
    "                my_species = my_species.replace(\"[\", \"\")\n",
    "                my_species = my_species.replace(\"]\", \"\")\n",
    "                \n",
    "                if my_species != \"\":\n",
    "                    \n",
    "                    taxid_to_species[taxid] = my_species\n",
    "                    contig_taxid[strings[1]] = taxid\n",
    "                    \n",
    "                    if taxid not in taxid_list:\n",
    "                        taxid_list.append(taxid)\n",
    "                        \n",
    "                    if my_species in species_names_taxid:\n",
    "                        species_names_taxid[my_species].add(taxid)\n",
    "                    else:\n",
    "                        species_names_taxid[my_species]=set([taxid])\n",
    "\n",
    "                    if taxid not in taxid_contigs:\n",
    "                        taxid_contigs[taxid] = [strings[1]]\n",
    "                    else:\n",
    "                        taxid_contigs[taxid].append(strings[1])\n",
    "            \n",
    "                    if taxid not in taxid_total_len:\n",
    "                        taxid_total_len[taxid] = contig_lengths[strings[1]]\n",
    "                    else:\n",
    "                        taxid_total_len[taxid] += contig_lengths[strings[1]]\n",
    "                        \n",
    "                    if my_species not in species_names_taxid_length:\n",
    "                        species_names_taxid_length[my_species] = {}\n",
    "                        species_names_taxid_length[my_species][taxid] = contig_lengths[strings[1]]\n",
    "                    else:\n",
    "                        if taxid not in species_names_taxid_length[my_species]:\n",
    "                            species_names_taxid_length[my_species][taxid] = contig_lengths[strings[1]]\n",
    "                        else:\n",
    "                            species_names_taxid_length[my_species][taxid] += contig_lengths[strings[1]]\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for species in species_names_taxid_length:\n",
    "    sorted_taxids = {k: v for k, v in sorted(species_names_taxid_length[species].items(), reverse=True, key=lambda item: item[1])}\n",
    "    species_names_taxid_length[species] = sorted_taxids\n",
    "# species_names_taxid_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MD2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath = project_path\n",
    "fpath = project_path+n_species+\"final.contigs.fa.lst\"\n",
    "\n",
    "\n",
    "def get_seqs(path):\n",
    "    active = \"\"\n",
    "    \n",
    "    for line in open(path):\n",
    "        if line[0] == \">\":\n",
    "            active += line\n",
    "        elif len(active) > 0 and len(line.strip()) != 0:\n",
    "            active += line\n",
    "        elif len(line.strip()) == 0 and len(active) > 0:\n",
    "            yield active\n",
    "            active = \"\"\n",
    "    if len(active) > 0:\n",
    "        yield active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_aa_list = {}\n",
    "gene_seq = {}\n",
    "\n",
    "genes_contigs_c = {}\n",
    "\n",
    "gene_species_mapped_c = {}\n",
    "\n",
    "unmapped_count = 0\n",
    "\n",
    "mapped_gene_lengths = []\n",
    "unmapped_gene_lengths = []\n",
    "\n",
    "contigs_containing_genes = []\n",
    "\n",
    "for seq in get_seqs(fpath):\n",
    "    if \"_aa|\" in seq:\n",
    "        \n",
    "        strings = seq.split(\"|\")\n",
    "        \n",
    "        gene_id = strings[0][1:]\n",
    "        \n",
    "        has_bin = False\n",
    "        \n",
    "        start_n = 'k141_'\n",
    "        end_n = ''\n",
    "            \n",
    "        contig_num = int(re.search('%s(.*)%s' % (start_n, end_n), seq.split(\">\")[-1].split(\" \")[0]).group(1))\n",
    "        \n",
    "        genes_contigs_c[gene_id] = contig_num\n",
    "        \n",
    "        gene_seq[gene_id] = seq\n",
    "        \n",
    "        if 'k141_'+str(contig_num) in contig_taxid:\n",
    "            \n",
    "            if contig_taxid['k141_'+str(contig_num)] in taxid_to_species:\n",
    "                gene_species_mapped_c[gene_id] = taxid_to_species[contig_taxid['k141_'+str(contig_num)]]\n",
    "                has_bin = True\n",
    "            \n",
    "        if not has_bin:\n",
    "            gene_species_mapped[gene_id] = \"unmapped\"\n",
    "            unmapped_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of genes:\", len(genes_contigs_c))\n",
    "print(\"Number of genes mapped:\", len(gene_species_mapped_c))\n",
    "print(\"Number of genes unmapped:\", len(genes_contigs_c) - len(gene_species_mapped_c))\n",
    "print((len(gene_species_mapped_c))/len(genes_contigs_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data we want to write to the worksheet.\n",
    "gene_species = {\"GeneID\":\"Annotation\"}\n",
    "\n",
    "with open(project_path+n_species+\"/final.contigs.genes.faa\", \"w\") as aafile:\n",
    "    for gene in genes_contigs:\n",
    "        \n",
    "        gene_id = gene\n",
    "        \n",
    "        if gene_id in gene_species_mapped_c:\n",
    "            gene_species[gene_id] = \"[\"+gene_species_mapped_c[gene].replace(\"_\", \" \")+\"]\"\n",
    "        else:\n",
    "            gene_species[gene_id] = \"-\"\n",
    "            \n",
    "        aafile.write(gene_seq[gene])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = collections.OrderedDict(sorted(gene_species.items()))\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook(project_path+n_species+\"/\"+n_species.lower()[:-1]+\".contigs.genes.species.mapped.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Start from the first cell. Rows and columns are zero indexed.\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "print(len(od.items()))\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for gene, species in od.items():\n",
    "    worksheet.write(row, col,     gene)\n",
    "    worksheet.write(row, col + 1, species)\n",
    "    row += 1\n",
    "    \n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
