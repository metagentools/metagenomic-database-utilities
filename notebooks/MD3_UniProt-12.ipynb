{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/media/vijinim/data/Experiments/Data/FUDAN/Uniprot-12/\"\n",
    "\n",
    "# kraken2 --confidence 0.1 \n",
    "# https://www.biostars.org/p/402619/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import subprocess\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import glob\n",
    "import xlsxwriter\n",
    "import collections\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from Bio import SeqIO\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get contig lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_lengths = {}\n",
    "\n",
    "for index, record in enumerate(SeqIO.parse(project_path+\"final.contigs.fa\", \"fasta\")):\n",
    "    contig_lengths[record.id] = len(record.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get kraken result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_total_len = {}\n",
    "\n",
    "species_names_taxid = {}\n",
    "\n",
    "taxid_list = []\n",
    "\n",
    "contig_taxid = {}\n",
    "\n",
    "taxid_contigs = {}\n",
    "\n",
    "taxid_to_species = {}\n",
    "\n",
    "species_names_taxid_length = {}\n",
    "\n",
    "with open(project_path+\"MEGAHIT_new_kraken_res_0.1.txt\", \"r\") as myfile:\n",
    "    for line in myfile.readlines():\n",
    "        strings = line.strip().split(\"\\t\")\n",
    "        \n",
    "        if strings[0] == \"C\":\n",
    "            \n",
    "            species_strings = strings[2].split(\" \")\n",
    "            \n",
    "            if len(species_strings) > 3 and \"unclassified\" not in strings[2] and \"complex\" not in strings[2] and \" group \" not in strings[2] and \"Human\" not in strings[2] and \"phage\" not in strings[2] and \"cellular organisms\" not in strings[2]:\n",
    "                \n",
    "                taxid = species_strings[-1][:-1]\n",
    "                \n",
    "                my_species = \"\"\n",
    "                \n",
    "                if species_strings[0] == \"Candidatus\":\n",
    "                    my_species = species_strings[0] + \" \" + species_strings[1] + \" \" + species_strings[2]\n",
    "                    \n",
    "                elif species_strings[1] != \"sp.\":\n",
    "                    my_species = species_strings[0] + \" \" + species_strings[1]\n",
    "                elif \"(taxid\" not in species_strings[3]:\n",
    "                    my_species = strings[2].split(\"(taxid\")[0]\n",
    "                    \n",
    "                my_species = my_species.replace(\"[\", \"\")\n",
    "                my_species = my_species.replace(\"]\", \"\")\n",
    "                \n",
    "                if my_species != \"\":\n",
    "                    \n",
    "                    taxid_to_species[taxid] = my_species\n",
    "                    contig_taxid[strings[1]] = taxid\n",
    "                    \n",
    "                    if taxid not in taxid_list:\n",
    "                        taxid_list.append(taxid)\n",
    "                        \n",
    "                    if my_species in species_names_taxid:\n",
    "                        species_names_taxid[my_species].add(taxid)\n",
    "                    else:\n",
    "                        species_names_taxid[my_species]=set([taxid])\n",
    "\n",
    "                    if taxid not in taxid_contigs:\n",
    "                        taxid_contigs[taxid] = [strings[1]]\n",
    "                    else:\n",
    "                        taxid_contigs[taxid].append(strings[1])\n",
    "            \n",
    "                    if taxid not in taxid_total_len:\n",
    "                        taxid_total_len[taxid] = contig_lengths[strings[1]]\n",
    "                    else:\n",
    "                        taxid_total_len[taxid] += contig_lengths[strings[1]]\n",
    "                        \n",
    "                    if my_species not in species_names_taxid_length:\n",
    "                        species_names_taxid_length[my_species] = {}\n",
    "                        species_names_taxid_length[my_species][taxid] = contig_lengths[strings[1]]\n",
    "                    else:\n",
    "                        if taxid not in species_names_taxid_length[my_species]:\n",
    "                            species_names_taxid_length[my_species][taxid] = contig_lengths[strings[1]]\n",
    "                        else:\n",
    "                            species_names_taxid_length[my_species][taxid] += contig_lengths[strings[1]]\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for species in species_names_taxid_length:\n",
    "    sorted_taxids = {k: v for k, v in sorted(species_names_taxid_length[species].items(), reverse=True, key=lambda item: item[1])}\n",
    "    species_names_taxid_length[species] = sorted_taxids\n",
    "# species_names_taxid_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download genomes of taxids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_dates = {}\n",
    "taxid_urls = {}\n",
    "taxid_file_path = {}\n",
    "taxid_assembly_level = {}\n",
    "taxid_present = {}\n",
    "\n",
    "for taxid in taxid_list:\n",
    "    taxid_urls[taxid] = \"\"\n",
    "    taxid_file_path[taxid] = \"\"\n",
    "    taxid_present[taxid] = False\n",
    "\n",
    "with open(\"/media/vijinim/data/Experiments/Data/Bacteria_Refs/assembly_summary.txt\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter='\\t')\n",
    "    line_count = 0\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        \n",
    "        if not row[0].startswith(\"#\"):\n",
    "            \n",
    "            if row[5] in taxid_list:\n",
    "                \n",
    "                name = row[0]\n",
    "                taxid = row[5]\n",
    "                version_status = row[10]\n",
    "                assembly_level = row[11]\n",
    "                genome_rep = row[13]\n",
    "                rel_date = row[14].split(\"/\")\n",
    "                url = row[19]\n",
    "                \n",
    "                myurl = url+\"/\"+url.split(\"/\")[-1]+\"_genomic.fna.gz\"\n",
    "                            \n",
    "                local_file = url.split(\"/\")[-1]+\"_genomic.fna.gz\"\n",
    "\n",
    "                myfile_name = project_path+\"Assemblies/\"+url.split(\"/\")[-1]+\"_genomic.fna\"\n",
    "                \n",
    "                if version_status == \"latest\" and genome_rep == \"Full\":\n",
    "                \n",
    "                    if taxid not in taxid_dates:\n",
    "\n",
    "                        if assembly_level in [\"Complete Genome\", \"Contig\", \"Chromosome\"]:\n",
    "\n",
    "                            if os.path.exists(\"/media/vijinim/data/Experiments/Data/Bacteria_Refs/bacterial_references/\"+local_file):\n",
    "\n",
    "                                subprocess.run(\"cp /media/vijinim/data/Experiments/Data/Bacteria_Refs/bacterial_references/\"+local_file+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "\n",
    "                            else:\n",
    "                                subprocess.run(\"rsync --copy-links --times --verbose \"+myurl.replace(\"ftp:\", \"rsync:\")+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "#                                 subprocess.run(\"wget \"+myurl, shell=True)\n",
    "#                                 subprocess.run(\"mv \"+local_file+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "\n",
    "                            if os.path.exists(project_path+\"Assemblies/\"+local_file):\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    with gzip.open(project_path+\"Assemblies/\"+local_file, 'rb') as f_in:\n",
    "                                        with open(myfile_name, 'wb') as f_out:\n",
    "                                            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "                                    subprocess.run(\"rm \"+project_path+\"Assemblies/\"+local_file, shell=True)\n",
    "\n",
    "                                    taxid_dates[taxid] = rel_date\n",
    "                                    taxid_urls[taxid] = url\n",
    "                                    taxid_file_path[taxid] = myfile_name\n",
    "                                    taxid_assembly_level[taxid] = assembly_level\n",
    "                                    taxid_present[taxid] = True\n",
    "\n",
    "                                except:\n",
    "\n",
    "                                    if os.path.exists(project_path+\"Assemblies/\"+local_file):\n",
    "                                        subprocess.run(\"rm \"+project_path+\"Assemblies/\"+local_file, shell=True)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        present = datetime.now()\n",
    "                        \n",
    "\n",
    "                        old_diff = present - datetime(int(taxid_dates[taxid][0]), int(taxid_dates[taxid][1]), int(taxid_dates[taxid][2]))\n",
    "                        new_diff = present - datetime(int(rel_date[0]), int(rel_date[1]), int(rel_date[2]))\n",
    "\n",
    "                        if old_diff > new_diff:\n",
    "\n",
    "                            if not ((assembly_level!=\"Complete Genome\" and taxid_assembly_level[taxid]==\"Complete Genome\") or (assembly_level==\"Contig\" and taxid_assembly_level[taxid]==\"Chromosome\")):\n",
    "\n",
    "\n",
    "                                if not os.path.exists(project_path+\"Assemblies/\"+local_file):\n",
    "\n",
    "                                    if os.path.exists(\"/media/vijinim/data/Experiments/Data/Bacteria_Refs/bacterial_references/\"+local_file):\n",
    "\n",
    "                                        subprocess.run(\"cp /media/vijinim/data/Experiments/Data/Bacteria_Refs/bacterial_references/\"+local_file+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "\n",
    "                                    else:\n",
    "                                        subprocess.run(\"rsync --copy-links --times --verbose \"+myurl.replace(\"ftp:\", \"rsync:\")+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "#                                         subprocess.run(\"wget \"+myurl, shell=True)\n",
    "#                                         subprocess.run(\"mv \"+local_file+\" \"+project_path+\"Assemblies\", shell=True)\n",
    "\n",
    "                                    if os.path.exists(project_path+\"Assemblies/\"+local_file):\n",
    "\n",
    "                                        try:\n",
    "\n",
    "                                            with gzip.open(project_path+\"Assemblies/\"+local_file, 'rb') as f_in:\n",
    "                                                with open(myfile_name, 'wb') as f_out:\n",
    "                                                    shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "                                            if taxid_file_path[taxid] != \"\":\n",
    "                                                if os.path.exists(taxid_file_path[taxid]):\n",
    "                                                    subprocess.run(\"rm \"+taxid_file_path[taxid], shell=True)\n",
    "\n",
    "                                            subprocess.run(\"rm \"+project_path+\"Assemblies/\"+local_file, shell=True)\n",
    "\n",
    "                                            taxid_dates[taxid] = rel_date\n",
    "                                            taxid_urls[taxid] = url\n",
    "                                            taxid_file_path[taxid] = myfile_name\n",
    "                                            taxid_assembly_level[taxid] = assembly_level\n",
    "                                            taxid_present[taxid] = True\n",
    "\n",
    "                                        except:\n",
    "\n",
    "                                            if os.path.exists(project_path+\"Assemblies/\"+local_file):\n",
    "                                                subprocess.run(\"rm \"+project_path+\"Assemblies/\"+local_file, shell=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download genomes of missed species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_path = {}\n",
    "not_present_species = []\n",
    "\n",
    "present_count = 0\n",
    "\n",
    "for ref in species_names_taxid_length:\n",
    "    file_present = False\n",
    "    for taxid in species_names_taxid_length[ref].keys():\n",
    "        if taxid_file_path[taxid] != \"\":\n",
    "            file_present = True\n",
    "            species_path[ref] = taxid_file_path[taxid]\n",
    "            break\n",
    "    if file_present:\n",
    "        present_count += 1\n",
    "    else:\n",
    "        print(ref, \"not present\", list(species_names_taxid_length[ref].keys())[0])\n",
    "        not_present_species.append(ref)\n",
    "        \n",
    "print(present_count, len(not_present_species))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename and copy species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for taxid in taxid_present:\n",
    "    if taxid_present[taxid]:\n",
    "        subprocess.run(\"cp \"+taxid_file_path[taxid]+\" \"+project_path+\"Reference_Sequences/\"+taxid+\".fna\", shell=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get length of ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_file_len = {}\n",
    "\n",
    "for taxid in taxid_present:\n",
    "    command = 'grep -v \">\" '+taxid_file_path[taxid]+' | wc | awk \\'{print $3-$1}\\''\n",
    "    n = subprocess.check_output(command, shell=True)\n",
    "\n",
    "    taxid_file_len[taxid] = int(n.decode(\"utf-8\").strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_coverages = {}\n",
    "\n",
    "with open(project_path+\"contig_coverages.tsv\", \"r\") as myfile:\n",
    "    \n",
    "    for line in myfile.readlines():\n",
    "        \n",
    "        if not line.startswith(\"Contig\"):\n",
    "            \n",
    "            strings = line.strip().split()\n",
    "        \n",
    "            contig_coverages[strings[0]] = float(strings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species length and total contig length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_ref_length = {}\n",
    "species_contig_length = {}\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    species_ref_length[species] = 0\n",
    "    species_contig_length[species] = 0\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "        \n",
    "    total_sum = 0\n",
    "    total_contig_length_sum = 0\n",
    "    species_count = 0\n",
    "\n",
    "    for taxid in species_names_taxid_length[species]:\n",
    "        \n",
    "        if taxid in taxid_file_len:\n",
    "            if taxid_file_len[taxid] != 0:\n",
    "                total_sum += taxid_file_len[taxid]\n",
    "                total_contig_length_sum += species_names_taxid_length[species][taxid]\n",
    "                species_count += 1\n",
    "    \n",
    "    species_contig_length[species] = total_contig_length_sum\n",
    "    \n",
    "    if species_count != 0:\n",
    "        species_ref_length[species] = total_sum/species_count\n",
    "    else:\n",
    "        species_ref_length[species] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_coverages = {}\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    species_coverages[species] = 0\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "        \n",
    "    total_sum = 0\n",
    "    total_contig_length = 0\n",
    "\n",
    "    for taxid in species_names_taxid_length[species]:\n",
    "\n",
    "        for contig in taxid_contigs[taxid]:\n",
    "            total_sum += contig_lengths[contig]*contig_coverages[contig]\n",
    "            total_contig_length += contig_lengths[contig]\n",
    "\n",
    "    if total_contig_length != 0:\n",
    "        species_coverages[species] = total_sum/total_contig_length\n",
    "    else:\n",
    "        species_coverages[species] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species reference genome coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_genome_coverages = {}\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    species_genome_coverages[species] = 0\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    \n",
    "    total_contig_length = 0\n",
    "\n",
    "    for taxid in species_names_taxid_length[species]:\n",
    "        \n",
    "        for contig in taxid_contigs[taxid]:\n",
    "            total_contig_length += contig_lengths[contig]\n",
    "            \n",
    "    if total_contig_length != 0 and species_ref_length[species] != 0:\n",
    "        species_genome_coverages[species] = total_contig_length/species_ref_length[species]\n",
    "    else:\n",
    "        species_genome_coverages[species] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species relative abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_rel_abundance = {}\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    species_rel_abundance[species] = 0\n",
    "    \n",
    "total_reads_mapped = 0\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "        \n",
    "    species_reads = 0\n",
    "\n",
    "    for taxid in species_names_taxid_length[species]:\n",
    "        \n",
    "        for contig in taxid_contigs[taxid]:\n",
    "            species_reads += contig_lengths[contig]*contig_coverages[contig]\n",
    "            total_reads_mapped += contig_lengths[contig]*contig_coverages[contig]\n",
    "    \n",
    "    species_rel_abundance[species] = species_reads\n",
    "    \n",
    "for species in species_names_taxid_length:\n",
    "    species_rel_abundance[species] = species_rel_abundance[species]/total_reads_mapped\n",
    "\n",
    "sorted_species = {k: v for k, v in sorted(species_rel_abundance.items(), reverse=True, key=lambda item: item[1])}\n",
    "species_rel_abundance = sorted_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species taxanomic abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_tax_abundance = {}\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    species_tax_abundance[species] = 0\n",
    "    \n",
    "total_coverage = 0\n",
    "\n",
    "for species in species_names_taxid_length:\n",
    "    \n",
    "    species_tax_abundance[species] = species_coverages[species]\n",
    "    total_coverage += species_coverages[species]\n",
    "    \n",
    "for species in species_names_taxid_length:\n",
    "    species_tax_abundance[species] = species_tax_abundance[species]/total_coverage\n",
    "\n",
    "sorted_species = {k: v for k, v in sorted(species_tax_abundance.items(), reverse=True, key=lambda item: item[1])}\n",
    "species_tax_abundance = sorted_species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and copy species above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n = 1\n",
    "\n",
    "total_tax_abundance = 0\n",
    "\n",
    "folder=\"Species_12/\"\n",
    "\n",
    "print(\"Species \\t Relative abundance \\t Taxonomic abundance \\t Genome coverage\")\n",
    "\n",
    "with open(project_path+folder+\"species_stats.tsv\", \"w\") as myfile:\n",
    "    \n",
    "    myfile.write(\"Species name\\tRelative abundance\\tTaxonomic abundance\\tGenome coverage\\tSpecies coverage\\n\")\n",
    "    \n",
    "    for species in species_rel_abundance:\n",
    "\n",
    "        if species_rel_abundance[species] > 0.005:\n",
    "            \n",
    "            myfile.write(species+\"\\t\"+str(species_rel_abundance[species])+\"\\t\"+str(species_tax_abundance[species])+\"\\t\"+str(species_genome_coverages[species])+\"\\t\"+str(species_coverages[species])+\"\\n\")\n",
    "\n",
    "            total_tax_abundance += species_tax_abundance[species]\n",
    "            \n",
    "            for taxid in species_names_taxid_length[species]:\n",
    "\n",
    "                subprocess.run(\"cp \"+taxid_file_path[taxid]+\" \"+project_path+folder+\"Reference_Sequences/\"+taxid+\".fna\", shell=True)\n",
    "\n",
    "            print(s_n, species, \"\\t\", species_rel_abundance[species], \"\\t\", species_tax_abundance[species], \"\\t\", species_genome_coverages[species], \"\\t\", species_coverages[species])\n",
    "            s_n+=1\n",
    "        \n",
    "# print(\"total_tax_abundance:\", total_tax_abundance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MD3 database\n",
    "\n",
    "## Get gene sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_species = folder\n",
    "\n",
    "ppath = project_path\n",
    "fpath = project_path+n_species+\"final.contigs.fa.lst\"\n",
    "\n",
    "\n",
    "def get_seqs(path):\n",
    "    active = \"\"\n",
    "    \n",
    "    for line in open(path):\n",
    "        if line[0] == \">\":\n",
    "            active += line\n",
    "        elif len(active) > 0 and len(line.strip()) != 0:\n",
    "            active += line\n",
    "        elif len(line.strip()) == 0 and len(active) > 0:\n",
    "            yield active\n",
    "            active = \"\"\n",
    "    if len(active) > 0:\n",
    "        yield active\n",
    "\n",
    "gene_nt_seq = {}\n",
    "\n",
    "for seq in get_seqs(fpath):\n",
    "    if \"_nt|\" in seq:\n",
    "        \n",
    "        strings = seq.split(\"|\")\n",
    "        \n",
    "        gene_id = strings[0][1:]\n",
    "        \n",
    "        gene_nt_seq[gene_id] = seq\n",
    "        \n",
    "with open(ppath+n_species+\"/all_genes.fna\", \"w\") as ntfile:\n",
    "    for gene in gene_nt_seq:\n",
    "        ntfile.write(gene_nt_seq[gene])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lengths = {}\n",
    "\n",
    "lenthgs_genes = []\n",
    "\n",
    "for index, record in enumerate(SeqIO.parse(project_path+n_species+\"/all_genes.fna\", \"fasta\")):\n",
    "    \n",
    "    strings = record.id.split(\"|\")\n",
    "        \n",
    "    gene_id = strings[0]\n",
    "    \n",
    "#     print(gene_id)\n",
    "    \n",
    "    gene_lengths[gene_id] = len(record.seq)\n",
    "    lenthgs_genes.append(len(record.seq))\n",
    "    \n",
    "print(\"Maximum gene length:\", max(lenthgs_genes))\n",
    "print(\"Minimum gene length:\", min(lenthgs_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align genes to refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"$project_path\"\"$folder\"Reference_Sequences/*.fna > \"$project_path\"\"$folder\"Reference_Sequences/refs.fna\n",
    "\n",
    "!minimap2 -t 8 \"$project_path\"\"$folder\"Reference_Sequences/refs.fna \"$project_path\"\"$folder\"all_genes.fna > \"$project_path\"\"$folder\"all_genes.paf\n",
    "\n",
    "# !rm \"$project_path\"\"$folder\"Reference_Sequences/refs.fna\n",
    "\n",
    "contig_ref = defaultdict(list)\n",
    "contig_ref_aln_length = defaultdict(list)\n",
    "contig_length = {}\n",
    "\n",
    "for line in open(project_path+folder+'all_genes.paf'):\n",
    "    data = line.strip().split('\\t')\n",
    "#     1\tstring\tQuery sequence name\n",
    "#     2\tint\tQuery sequence length\n",
    "#     3\tint\tQuery start (0-based; BED-like; closed)\n",
    "#     4\tint\tQuery end (0-based; BED-like; open)\n",
    "#     5\tchar\tRelative strand: \"+\" or \"-\"\n",
    "#     6\tstring\tTarget sequence name\n",
    "#     7\tint\tTarget sequence length\n",
    "#     8\tint\tTarget start on original strand (0-based)\n",
    "#     9\tint\tTarget end on original strand (0-based)\n",
    "#     10\tint\tNumber of residue matches\n",
    "#     11\tint\tAlignment block length\n",
    "#     12\tint\tMapping quality (0-255; 255 for missing)\n",
    "\n",
    "    qname = data[0]\n",
    "    qlen = int(data[1])\n",
    "    qstart = int(data[2])\n",
    "    qqend = int(data[3])\n",
    "    char = data[4]\n",
    "    tname = data[5]\n",
    "    tlen = int(data[6])\n",
    "    tstart = int(data[7])\n",
    "    aln_len = int(data[10])\n",
    "    flag = int(data[11])\n",
    "\n",
    "    if not flag == 255:\n",
    "\n",
    "        contig_ref[qname].append(tname)\n",
    "        contig_ref_aln_length[qname].append(aln_len)\n",
    "        contig_length[qname] = qlen\n",
    "        \n",
    "        \n",
    "threshold = 0.5\n",
    "\n",
    "with open(project_path+folder+'all_genes.output', 'w+') as f:\n",
    "    for k, v in contig_ref.items():\n",
    "        best = None\n",
    "        best_len = 0\n",
    "        c_len = contig_length[k]\n",
    "\n",
    "        if len(v) > 1:\n",
    "            \n",
    "            align_sum = 0\n",
    "            \n",
    "            for ref, l in zip(contig_ref[k], contig_ref_aln_length[k]):\n",
    "                \n",
    "                align_sum += l\n",
    "                \n",
    "            if align_sum >= threshold * c_len and best_len < align_sum:\n",
    "                best_len = align_sum\n",
    "                best = ref\n",
    "                    \n",
    "        elif contig_ref_aln_length[k][0] >= threshold * c_len:\n",
    "            best = contig_ref[k][0]\n",
    "            best_len = contig_ref_aln_length[k][0]\n",
    "        else:\n",
    "            best = 'POOR MAPPING'\n",
    "        f.write(f'{k}\\t{best}\\t{best_len}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ref IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_files = glob.glob(project_path+n_species+'/Reference_Sequences/*.fna')\n",
    "\n",
    "ref_ids = {}\n",
    "\n",
    "for ref in reference_files:\n",
    "    ref_name = ref.split(\"/\")[-1][:-4]\n",
    "    pp = !grep \"^>\" \"$ref\"\n",
    "    \n",
    "    for item in pp:\n",
    "        myid = item.split(\" \")[0][1:]\n",
    "        \n",
    "        if ref_name not in ref_ids:\n",
    "            ref_ids[ref_name] = [myid]\n",
    "        else:\n",
    "            ref_ids[ref_name].append(myid)\n",
    "            \n",
    "len(ref_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get mapped species to genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_gene_bins = {}\n",
    "\n",
    "with open(project_path+n_species+'/all_genes.output', mode='r') as myfile:\n",
    "    \n",
    "    for line in myfile.readlines():\n",
    "        \n",
    "        strings = line.strip().split(\"\\t\")\n",
    "\n",
    "        gene_num = strings[0].split(\"|\")[0]\n",
    "        \n",
    "        for ref in ref_ids:\n",
    "            if strings[1] in ref_ids[ref]:\n",
    "                if gene_num not in mapped_gene_bins:\n",
    "                    mapped_gene_bins[gene_num] = ref\n",
    "                break\n",
    "    \n",
    "print(len(mapped_gene_bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get aa seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_aa_list = {}\n",
    "gene_seq = {}\n",
    "\n",
    "genes_contigs = {}\n",
    "\n",
    "gene_species_mapped = {}\n",
    "\n",
    "unmapped_count = 0\n",
    "\n",
    "mapped_gene_lengths = []\n",
    "unmapped_gene_lengths = []\n",
    "\n",
    "contigs_containing_genes = []\n",
    "\n",
    "for seq in get_seqs(fpath):\n",
    "    if \"_aa|\" in seq:\n",
    "        \n",
    "        strings = seq.split(\"|\")\n",
    "        \n",
    "        gene_id = strings[0][1:]\n",
    "        \n",
    "        start_n = 'k141_'\n",
    "        end_n = ''\n",
    "        \n",
    "        contig_id = seq.split(\">\")[-1].split(\" \")[0]\n",
    "        \n",
    "        contig_num = int(re.search('%s(.*)%s' % (start_n, end_n), seq.split(\">\")[-1].split(\" \")[0]).group(1))\n",
    "        \n",
    "        strings = seq.split(\">\")\n",
    "        \n",
    "        gene_id = strings[1].strip().split(\"|\")[0]\n",
    "        \n",
    "        gene_seq[gene_id] = seq\n",
    "        \n",
    "        genes_contigs[gene_id] = contig_num\n",
    "        \n",
    "        has_bin = False\n",
    "\n",
    "        if gene_id in mapped_gene_bins:\n",
    "            \n",
    "            if taxid_present[mapped_gene_bins[gene_id]]:\n",
    "\n",
    "                gene_species_mapped[gene_id] = taxid_to_species[mapped_gene_bins[gene_id]]\n",
    "\n",
    "                has_bin = True\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if contig_id in contig_taxid:\n",
    "                    gene_species_mapped[gene_id] = taxid_to_species[contig_taxid[contig_id]]\n",
    "                    has_bin = True\n",
    "\n",
    "        if not has_bin:\n",
    "            gene_species_mapped[gene_id] = \"unmapped\"\n",
    "            unmapped_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gene_species_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of genes:\", len(gene_lengths))\n",
    "print(\"Number of genes mapped:\", len(gene_lengths)-unmapped_count)\n",
    "print((len(gene_lengths)-unmapped_count)/len(gene_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data we want to write to the worksheet.\n",
    "gene_species = {\"GeneID\":\"Annotation\"}\n",
    "\n",
    "with open(project_path+n_species+\"/all_genes.faa\", \"w\") as aafile:\n",
    "    for gene in gene_species_mapped:\n",
    "        \n",
    "        gene_id = gene\n",
    "        \n",
    "        if gene_species_mapped[gene] == \"unmapped\":\n",
    "            gene_species[gene_id] = \"-\"\n",
    "        else:\n",
    "            gene_species[gene_id] = \"[\"+gene_species_mapped[gene].replace(\"_\", \" \")+\"]\"\n",
    "            \n",
    "        aafile.write(gene_seq[gene])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = collections.OrderedDict(sorted(gene_species.items()))\n",
    "\n",
    "# Create a workbook and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook(project_path+n_species+\"/\"+n_species.lower()[:-1]+\".genes.species.mapped.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Start from the first cell. Rows and columns are zero indexed.\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "print(len(od.items()))\n",
    "\n",
    "# Iterate over the data and write it out row by row.\n",
    "for gene, species in od.items():\n",
    "    worksheet.write(row, col,     gene)\n",
    "    worksheet.write(row, col + 1, species)\n",
    "    row += 1\n",
    "    \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get species count in contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_in_contig = {}\n",
    "\n",
    "for gene in genes_contigs:\n",
    "    \n",
    "    if gene in gene_species_mapped:\n",
    "        \n",
    "        if gene_species_mapped[gene] != \"unmapped\":\n",
    "                \n",
    "            if genes_contigs[gene] not in species_in_contig:\n",
    "                species_in_contig[genes_contigs[gene]] = [gene_species_mapped[gene]]\n",
    "            else:\n",
    "                if gene_species_mapped[gene] not in species_in_contig[genes_contigs[gene]]:\n",
    "                    species_in_contig[genes_contigs[gene]].append(gene_species_mapped[gene])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_species_in_contig = {}\n",
    "\n",
    "for contig in species_in_contig:\n",
    "    \n",
    "    if len(species_in_contig[contig]) not in counts_species_in_contig:\n",
    "        counts_species_in_contig[len(species_in_contig[contig])] = 1\n",
    "    else:\n",
    "        counts_species_in_contig[len(species_in_contig[contig])] += 1\n",
    "        \n",
    "counts_species_in_contig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
